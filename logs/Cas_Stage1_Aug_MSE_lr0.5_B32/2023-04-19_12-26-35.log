[Wed Apr 19 12:26:35 2023|main.py|INFO] Task: Cas_Stage1_Aug_MSE_lr0.5_B32
[Wed Apr 19 12:26:35 2023|main.py|INFO] Training cascade stage 1
[Wed Apr 19 12:26:35 2023|main.py|INFO] Using device: cuda
[Wed Apr 19 12:26:35 2023|main.py|INFO] Using config: config\Cas_Stage1_Aug_MSE\Cas_Stage1_Aug_MSE_lr0.5_B32.yaml
[Wed Apr 19 12:26:35 2023|main.py|INFO] Train path: data/training_images_full_train.npz
[Wed Apr 19 12:26:35 2023|main.py|INFO] Train path 2: data/training_images_subset.npz
[Wed Apr 19 12:26:35 2023|main.py|INFO] Test path: data/training_images_full_test.npz
[Wed Apr 19 12:26:35 2023|main.py|INFO] Train augment: True
[Wed Apr 19 12:26:35 2023|main.py|INFO] Learning rate: 0.5
[Wed Apr 19 12:26:35 2023|main.py|INFO] Batch size: 32
[Wed Apr 19 12:26:35 2023|main.py|INFO] Num epochs: 100
[Wed Apr 19 12:26:35 2023|main.py|INFO] Save model: True
[Wed Apr 19 12:26:35 2023|main.py|INFO] Loss: MSE
[Wed Apr 19 12:26:35 2023|main.py|INFO] Log path: logs/Cas_Stage1_Aug_MSE_lr0.5_B32/2023-04-19_12-26-35.log
[Wed Apr 19 12:26:35 2023|main.py|INFO] Writer path: runs/Cas_Stage1_Aug_MSE_lr0.5_B32/2023-04-19_12-26-35
[Wed Apr 19 12:26:35 2023|main.py|INFO] Model name: resnet18
[Wed Apr 19 12:26:35 2023|main.py|INFO] Num outputs: 10
[Wed Apr 19 12:26:35 2023|main.py|INFO] Pretrained: True
[Wed Apr 19 12:26:35 2023|main.py|INFO] Load model: False
[Wed Apr 19 12:26:35 2023|main.py|INFO] Load path: None
[Wed Apr 19 12:26:35 2023|main.py|INFO] Loading data...
[Wed Apr 19 12:26:35 2023|main.py|INFO] Load dataset for cascade stage 1
[Wed Apr 19 12:26:39 2023|main.py|INFO] Initializing network resnet18 with 10 outputs...
[Wed Apr 19 12:26:40 2023|main.py|INFO] Network: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
[Wed Apr 19 12:26:40 2023|main.py|INFO] Initializing loss and optimizer...
[Wed Apr 19 12:26:40 2023|main.py|INFO] Loss: MSE
[Wed Apr 19 12:26:40 2023|main.py|INFO] Optimizer: Adam
[Wed Apr 19 12:26:40 2023|main.py|INFO] Initializing tensorboard writer at: runs/Cas_Stage1_Aug_MSE_lr0.5_B32/2023-04-19_12-26-35
[Wed Apr 19 12:26:40 2023|main.py|INFO] Training network...
[Wed Apr 19 12:39:02 2023|main.py|INFO] EPOCH [1/100] Train NME: 0.36112
[Wed Apr 19 12:39:02 2023|main.py|INFO] EPOCH [1/100] Test NME: 0.16902
[Wed Apr 19 12:39:02 2023|main.py|INFO] EPOCH [1/100] Learning rate: 0.50000
[Wed Apr 19 12:39:02 2023|main.py|INFO] EPOCH [1/100] NME improved from 1000.00000 to 0.16902
[Wed Apr 19 12:39:02 2023|main.py|INFO] EPOCH [1/100] Saving model to: checkpoints/Cas_Stage1_Aug_MSE_lr0.5_B32/2023-04-19_12-39-02_epoch_1_NME_0.16902.pth.tar
[Wed Apr 19 12:53:31 2023|main.py|INFO] EPOCH [2/100] Train NME: 0.16496
[Wed Apr 19 12:53:32 2023|main.py|INFO] EPOCH [2/100] Test NME: 0.13863
[Wed Apr 19 12:53:32 2023|main.py|INFO] EPOCH [2/100] Learning rate: 0.40000
[Wed Apr 19 12:53:32 2023|main.py|INFO] EPOCH [2/100] NME improved from 0.16902 to 0.13863
[Wed Apr 19 12:53:32 2023|main.py|INFO] EPOCH [2/100] Saving model to: checkpoints/Cas_Stage1_Aug_MSE_lr0.5_B32/2023-04-19_12-53-32_epoch_2_NME_0.13863.pth.tar
[Wed Apr 19 13:12:57 2023|main.py|INFO] EPOCH [3/100] Train NME: 0.15679
[Wed Apr 19 13:12:57 2023|main.py|INFO] EPOCH [3/100] Test NME: 0.14718
[Wed Apr 19 13:12:57 2023|main.py|INFO] EPOCH [3/100] Learning rate: 0.32000
[Wed Apr 19 13:25:14 2023|main.py|INFO] EPOCH [4/100] Train NME: 0.15149
[Wed Apr 19 13:25:14 2023|main.py|INFO] EPOCH [4/100] Test NME: 0.14364
[Wed Apr 19 13:25:14 2023|main.py|INFO] EPOCH [4/100] Learning rate: 0.25600
[Wed Apr 19 13:37:50 2023|main.py|INFO] EPOCH [5/100] Train NME: 0.14476
[Wed Apr 19 13:37:50 2023|main.py|INFO] EPOCH [5/100] Test NME: 0.14232
[Wed Apr 19 13:37:50 2023|main.py|INFO] EPOCH [5/100] Learning rate: 0.20480
[Wed Apr 19 13:50:11 2023|main.py|INFO] EPOCH [6/100] Train NME: 0.14328
[Wed Apr 19 13:50:12 2023|main.py|INFO] EPOCH [6/100] Test NME: 0.13272
[Wed Apr 19 13:50:12 2023|main.py|INFO] EPOCH [6/100] Learning rate: 0.16384
[Wed Apr 19 13:50:12 2023|main.py|INFO] EPOCH [6/100] NME improved from 0.13863 to 0.13272
[Wed Apr 19 13:50:12 2023|main.py|INFO] EPOCH [6/100] Saving model to: checkpoints/Cas_Stage1_Aug_MSE_lr0.5_B32/2023-04-19_13-50-12_epoch_6_NME_0.13272.pth.tar
[Wed Apr 19 14:02:14 2023|main.py|INFO] EPOCH [7/100] Train NME: 0.13864
[Wed Apr 19 14:02:15 2023|main.py|INFO] EPOCH [7/100] Test NME: 0.13460
[Wed Apr 19 14:02:15 2023|main.py|INFO] EPOCH [7/100] Learning rate: 0.13107
[Wed Apr 19 14:14:13 2023|main.py|INFO] EPOCH [8/100] Train NME: 0.13627
[Wed Apr 19 14:14:14 2023|main.py|INFO] EPOCH [8/100] Test NME: 0.13527
[Wed Apr 19 14:14:14 2023|main.py|INFO] EPOCH [8/100] Learning rate: 0.10486
[Wed Apr 19 14:26:11 2023|main.py|INFO] EPOCH [9/100] Train NME: 0.13548
[Wed Apr 19 14:26:11 2023|main.py|INFO] EPOCH [9/100] Test NME: 0.13974
[Wed Apr 19 14:26:11 2023|main.py|INFO] EPOCH [9/100] Learning rate: 0.08389
[Wed Apr 19 14:38:27 2023|main.py|INFO] EPOCH [10/100] Train NME: 0.13465
[Wed Apr 19 14:38:27 2023|main.py|INFO] EPOCH [10/100] Test NME: 0.13799
[Wed Apr 19 14:38:27 2023|main.py|INFO] EPOCH [10/100] Learning rate: 0.06711
[Wed Apr 19 14:50:31 2023|main.py|INFO] EPOCH [11/100] Train NME: 0.13466
[Wed Apr 19 14:50:32 2023|main.py|INFO] EPOCH [11/100] Test NME: 0.13689
[Wed Apr 19 14:50:32 2023|main.py|INFO] EPOCH [11/100] Learning rate: 0.05369
[Wed Apr 19 15:03:04 2023|main.py|INFO] EPOCH [12/100] Train NME: 0.13250
[Wed Apr 19 15:03:05 2023|main.py|INFO] EPOCH [12/100] Test NME: 0.13866
[Wed Apr 19 15:03:05 2023|main.py|INFO] EPOCH [12/100] Learning rate: 0.04295
[Wed Apr 19 15:16:04 2023|main.py|INFO] EPOCH [13/100] Train NME: 0.13105
[Wed Apr 19 15:16:04 2023|main.py|INFO] EPOCH [13/100] Test NME: 0.13656
[Wed Apr 19 15:16:04 2023|main.py|INFO] EPOCH [13/100] Learning rate: 0.03436
[Wed Apr 19 15:28:20 2023|main.py|INFO] EPOCH [14/100] Train NME: 0.13010
[Wed Apr 19 15:28:20 2023|main.py|INFO] EPOCH [14/100] Test NME: 0.13914
[Wed Apr 19 15:28:20 2023|main.py|INFO] EPOCH [14/100] Learning rate: 0.02749
[Wed Apr 19 15:40:12 2023|main.py|INFO] EPOCH [15/100] Train NME: 0.12883
[Wed Apr 19 15:40:12 2023|main.py|INFO] EPOCH [15/100] Test NME: 0.13986
[Wed Apr 19 15:40:12 2023|main.py|INFO] EPOCH [15/100] Learning rate: 0.02199
[Wed Apr 19 15:52:17 2023|main.py|INFO] EPOCH [16/100] Train NME: 0.12873
[Wed Apr 19 15:52:17 2023|main.py|INFO] EPOCH [16/100] Test NME: 0.13831
[Wed Apr 19 15:52:17 2023|main.py|INFO] EPOCH [16/100] Learning rate: 0.01759
[Wed Apr 19 16:04:32 2023|main.py|INFO] EPOCH [17/100] Train NME: 0.12854
[Wed Apr 19 16:04:32 2023|main.py|INFO] EPOCH [17/100] Test NME: 0.14031
[Wed Apr 19 16:04:32 2023|main.py|INFO] EPOCH [17/100] Learning rate: 0.01407
[Wed Apr 19 16:16:41 2023|main.py|INFO] EPOCH [18/100] Train NME: 0.12794
[Wed Apr 19 16:16:42 2023|main.py|INFO] EPOCH [18/100] Test NME: 0.13993
[Wed Apr 19 16:16:42 2023|main.py|INFO] EPOCH [18/100] Learning rate: 0.01126
[Wed Apr 19 16:28:26 2023|main.py|INFO] EPOCH [19/100] Train NME: 0.12799
[Wed Apr 19 16:28:27 2023|main.py|INFO] EPOCH [19/100] Test NME: 0.14038
[Wed Apr 19 16:28:27 2023|main.py|INFO] EPOCH [19/100] Learning rate: 0.00901
[Wed Apr 19 16:40:34 2023|main.py|INFO] EPOCH [20/100] Train NME: 0.12806
[Wed Apr 19 16:40:35 2023|main.py|INFO] EPOCH [20/100] Test NME: 0.14008
[Wed Apr 19 16:40:35 2023|main.py|INFO] EPOCH [20/100] Learning rate: 0.00721
[Wed Apr 19 16:52:05 2023|main.py|INFO] EPOCH [21/100] Train NME: 0.12701
[Wed Apr 19 16:52:06 2023|main.py|INFO] EPOCH [21/100] Test NME: 0.14031
[Wed Apr 19 16:52:06 2023|main.py|INFO] EPOCH [21/100] Learning rate: 0.00576
[Wed Apr 19 17:03:57 2023|main.py|INFO] EPOCH [22/100] Train NME: 0.12711
[Wed Apr 19 17:03:58 2023|main.py|INFO] EPOCH [22/100] Test NME: 0.14050
[Wed Apr 19 17:03:58 2023|main.py|INFO] EPOCH [22/100] Learning rate: 0.00461
[Wed Apr 19 17:15:32 2023|main.py|INFO] EPOCH [23/100] Train NME: 0.12714
[Wed Apr 19 17:15:33 2023|main.py|INFO] EPOCH [23/100] Test NME: 0.14270
[Wed Apr 19 17:15:33 2023|main.py|INFO] EPOCH [23/100] Learning rate: 0.00369
[Wed Apr 19 17:27:37 2023|main.py|INFO] EPOCH [24/100] Train NME: 0.12726
[Wed Apr 19 17:27:38 2023|main.py|INFO] EPOCH [24/100] Test NME: 0.14200
[Wed Apr 19 17:27:38 2023|main.py|INFO] EPOCH [24/100] Learning rate: 0.00295
[Wed Apr 19 17:39:50 2023|main.py|INFO] EPOCH [25/100] Train NME: 0.12727
[Wed Apr 19 17:39:51 2023|main.py|INFO] EPOCH [25/100] Test NME: 0.14132
[Wed Apr 19 17:39:51 2023|main.py|INFO] EPOCH [25/100] Learning rate: 0.00236
[Wed Apr 19 17:51:54 2023|main.py|INFO] EPOCH [26/100] Train NME: 0.12763
[Wed Apr 19 17:51:55 2023|main.py|INFO] EPOCH [26/100] Test NME: 0.14278
[Wed Apr 19 17:51:55 2023|main.py|INFO] EPOCH [26/100] Learning rate: 0.00189
[Wed Apr 19 18:03:58 2023|main.py|INFO] EPOCH [27/100] Train NME: 0.12845
[Wed Apr 19 18:03:58 2023|main.py|INFO] EPOCH [27/100] Test NME: 0.14294
[Wed Apr 19 18:03:58 2023|main.py|INFO] EPOCH [27/100] Learning rate: 0.00151
[Wed Apr 19 18:15:59 2023|main.py|INFO] EPOCH [28/100] Train NME: 0.12823
[Wed Apr 19 18:16:00 2023|main.py|INFO] EPOCH [28/100] Test NME: 0.14244
[Wed Apr 19 18:16:00 2023|main.py|INFO] EPOCH [28/100] Learning rate: 0.00121
[Wed Apr 19 18:27:58 2023|main.py|INFO] EPOCH [29/100] Train NME: 0.12749
[Wed Apr 19 18:27:59 2023|main.py|INFO] EPOCH [29/100] Test NME: 0.14167
[Wed Apr 19 18:27:59 2023|main.py|INFO] EPOCH [29/100] Learning rate: 0.00097
[Wed Apr 19 18:39:40 2023|main.py|INFO] EPOCH [30/100] Train NME: 0.12787
[Wed Apr 19 18:39:40 2023|main.py|INFO] EPOCH [30/100] Test NME: 0.14231
[Wed Apr 19 18:39:40 2023|main.py|INFO] EPOCH [30/100] Learning rate: 0.00077
[Wed Apr 19 18:51:23 2023|main.py|INFO] EPOCH [31/100] Train NME: 0.12821
[Wed Apr 19 18:51:23 2023|main.py|INFO] EPOCH [31/100] Test NME: 0.14331
[Wed Apr 19 18:51:23 2023|main.py|INFO] EPOCH [31/100] Learning rate: 0.00062
[Wed Apr 19 19:03:04 2023|main.py|INFO] EPOCH [32/100] Train NME: 0.12879
[Wed Apr 19 19:03:05 2023|main.py|INFO] EPOCH [32/100] Test NME: 0.14311
[Wed Apr 19 19:03:05 2023|main.py|INFO] EPOCH [32/100] Learning rate: 0.00050
[Wed Apr 19 19:14:34 2023|main.py|INFO] EPOCH [33/100] Train NME: 0.12919
[Wed Apr 19 19:14:35 2023|main.py|INFO] EPOCH [33/100] Test NME: 0.14294
[Wed Apr 19 19:14:35 2023|main.py|INFO] EPOCH [33/100] Learning rate: 0.00040
[Wed Apr 19 19:26:38 2023|main.py|INFO] EPOCH [34/100] Train NME: 0.12943
[Wed Apr 19 19:26:39 2023|main.py|INFO] EPOCH [34/100] Test NME: 0.14309
[Wed Apr 19 19:26:39 2023|main.py|INFO] EPOCH [34/100] Learning rate: 0.00032
[Wed Apr 19 19:38:42 2023|main.py|INFO] EPOCH [35/100] Train NME: 0.12879
[Wed Apr 19 19:38:42 2023|main.py|INFO] EPOCH [35/100] Test NME: 0.14407
[Wed Apr 19 19:38:42 2023|main.py|INFO] EPOCH [35/100] Learning rate: 0.00025
[Wed Apr 19 19:50:04 2023|main.py|INFO] EPOCH [36/100] Train NME: 0.12943
[Wed Apr 19 19:50:04 2023|main.py|INFO] EPOCH [36/100] Test NME: 0.14327
[Wed Apr 19 19:50:04 2023|main.py|INFO] EPOCH [36/100] Learning rate: 0.00020
[Wed Apr 19 20:01:37 2023|main.py|INFO] EPOCH [37/100] Train NME: 0.12975
[Wed Apr 19 20:01:37 2023|main.py|INFO] EPOCH [37/100] Test NME: 0.14286
[Wed Apr 19 20:01:37 2023|main.py|INFO] EPOCH [37/100] Learning rate: 0.00016
[Wed Apr 19 20:13:38 2023|main.py|INFO] EPOCH [38/100] Train NME: 0.12971
[Wed Apr 19 20:13:39 2023|main.py|INFO] EPOCH [38/100] Test NME: 0.14454
[Wed Apr 19 20:13:39 2023|main.py|INFO] EPOCH [38/100] Learning rate: 0.00013
[Wed Apr 19 20:25:10 2023|main.py|INFO] EPOCH [39/100] Train NME: 0.12977
[Wed Apr 19 20:25:10 2023|main.py|INFO] EPOCH [39/100] Test NME: 0.14295
[Wed Apr 19 20:25:10 2023|main.py|INFO] EPOCH [39/100] Learning rate: 0.00010
[Wed Apr 19 20:36:55 2023|main.py|INFO] EPOCH [40/100] Train NME: 0.12958
[Wed Apr 19 20:36:56 2023|main.py|INFO] EPOCH [40/100] Test NME: 0.14191
[Wed Apr 19 20:36:56 2023|main.py|INFO] EPOCH [40/100] Learning rate: 0.00008
[Wed Apr 19 20:48:20 2023|main.py|INFO] EPOCH [41/100] Train NME: 0.12987
[Wed Apr 19 20:48:20 2023|main.py|INFO] EPOCH [41/100] Test NME: 0.14425
[Wed Apr 19 20:48:20 2023|main.py|INFO] EPOCH [41/100] Learning rate: 0.00007
[Wed Apr 19 21:00:33 2023|main.py|INFO] EPOCH [42/100] Train NME: 0.12978
[Wed Apr 19 21:00:33 2023|main.py|INFO] EPOCH [42/100] Test NME: 0.14427
[Wed Apr 19 21:00:33 2023|main.py|INFO] EPOCH [42/100] Learning rate: 0.00005
[Wed Apr 19 21:12:08 2023|main.py|INFO] EPOCH [43/100] Train NME: 0.13025
[Wed Apr 19 21:12:09 2023|main.py|INFO] EPOCH [43/100] Test NME: 0.14291
[Wed Apr 19 21:12:09 2023|main.py|INFO] EPOCH [43/100] Learning rate: 0.00004
[Wed Apr 19 21:23:58 2023|main.py|INFO] EPOCH [44/100] Train NME: 0.13027
[Wed Apr 19 21:23:59 2023|main.py|INFO] EPOCH [44/100] Test NME: 0.14320
[Wed Apr 19 21:23:59 2023|main.py|INFO] EPOCH [44/100] Learning rate: 0.00003
[Wed Apr 19 21:35:13 2023|main.py|INFO] EPOCH [45/100] Train NME: 0.13019
[Wed Apr 19 21:35:13 2023|main.py|INFO] EPOCH [45/100] Test NME: 0.14292
[Wed Apr 19 21:35:13 2023|main.py|INFO] EPOCH [45/100] Learning rate: 0.00003
[Wed Apr 19 21:45:24 2023|main.py|INFO] EPOCH [46/100] Train NME: 0.12961
[Wed Apr 19 21:45:25 2023|main.py|INFO] EPOCH [46/100] Test NME: 0.14520
[Wed Apr 19 21:45:25 2023|main.py|INFO] EPOCH [46/100] Learning rate: 0.00002
[Wed Apr 19 22:00:12 2023|main.py|INFO] EPOCH [47/100] Train NME: 0.13017
[Wed Apr 19 22:00:14 2023|main.py|INFO] EPOCH [47/100] Test NME: 0.14517
[Wed Apr 19 22:00:14 2023|main.py|INFO] EPOCH [47/100] Learning rate: 0.00002
[Wed Apr 19 22:23:41 2023|main.py|INFO] EPOCH [48/100] Train NME: 0.13032
[Wed Apr 19 22:23:42 2023|main.py|INFO] EPOCH [48/100] Test NME: 0.14510
[Wed Apr 19 22:23:42 2023|main.py|INFO] EPOCH [48/100] Learning rate: 0.00001
[Wed Apr 19 22:39:17 2023|main.py|INFO] EPOCH [49/100] Train NME: 0.13011
[Wed Apr 19 22:39:17 2023|main.py|INFO] EPOCH [49/100] Test NME: 0.14387
[Wed Apr 19 22:39:17 2023|main.py|INFO] EPOCH [49/100] Learning rate: 0.00001
[Wed Apr 19 22:52:56 2023|main.py|INFO] EPOCH [50/100] Train NME: 0.12989
[Wed Apr 19 22:52:57 2023|main.py|INFO] EPOCH [50/100] Test NME: 0.14331
[Wed Apr 19 22:52:57 2023|main.py|INFO] EPOCH [50/100] Learning rate: 0.00001
