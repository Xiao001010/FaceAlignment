[Fri Apr 21 16:22:46 2023|main.py|INFO] Task: Cas_Stage1_Aug_Wing_lr0.5_B4
[Fri Apr 21 16:22:46 2023|main.py|INFO] Training cascade stage 1
[Fri Apr 21 16:22:46 2023|main.py|INFO] Using device: cuda
[Fri Apr 21 16:22:46 2023|main.py|INFO] Using config: config\Cas_Stage1_Aug_Wing\Cas_Stage1_Aug_Wing_lr0.5_B4.yaml
[Fri Apr 21 16:22:46 2023|main.py|INFO] Train path: data/training_images_full_train.npz
[Fri Apr 21 16:22:46 2023|main.py|INFO] Train path 2: data/training_images_subset.npz
[Fri Apr 21 16:22:46 2023|main.py|INFO] Test path: data/training_images_full_test.npz
[Fri Apr 21 16:22:46 2023|main.py|INFO] Train augment: True
[Fri Apr 21 16:22:46 2023|main.py|INFO] Learning rate: 0.5
[Fri Apr 21 16:22:46 2023|main.py|INFO] Batch size: 4
[Fri Apr 21 16:22:46 2023|main.py|INFO] Num epochs: 100
[Fri Apr 21 16:22:46 2023|main.py|INFO] Save model: True
[Fri Apr 21 16:22:46 2023|main.py|INFO] Loss: Wing
[Fri Apr 21 16:22:46 2023|main.py|INFO] Log path: logs/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_16-22-46.log
[Fri Apr 21 16:22:46 2023|main.py|INFO] Writer path: runs/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_16-22-46
[Fri Apr 21 16:22:46 2023|main.py|INFO] Model name: resnet18
[Fri Apr 21 16:22:46 2023|main.py|INFO] Num outputs: 10
[Fri Apr 21 16:22:46 2023|main.py|INFO] Pretrained: True
[Fri Apr 21 16:22:46 2023|main.py|INFO] Load model: False
[Fri Apr 21 16:22:46 2023|main.py|INFO] Load path: None
[Fri Apr 21 16:22:46 2023|main.py|INFO] Loading data...
[Fri Apr 21 16:22:46 2023|main.py|INFO] Load dataset for cascade stage 1
[Fri Apr 21 16:22:50 2023|main.py|INFO] Initializing network resnet18 with 10 outputs...
[Fri Apr 21 16:22:50 2023|main.py|INFO] Network: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
[Fri Apr 21 16:22:50 2023|main.py|INFO] Initializing loss and optimizer...
[Fri Apr 21 16:22:50 2023|main.py|INFO] Loss: Wing
[Fri Apr 21 16:22:50 2023|main.py|INFO] Optimizer: Adam
[Fri Apr 21 16:22:50 2023|main.py|INFO] Initializing tensorboard writer at: runs/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_16-22-46
[Fri Apr 21 16:22:50 2023|main.py|INFO] Training network...
[Fri Apr 21 16:38:58 2023|main.py|INFO] EPOCH [1/100] Train NME: 0.27559
[Fri Apr 21 16:38:59 2023|main.py|INFO] EPOCH [1/100] Test NME: 0.29142
[Fri Apr 21 16:38:59 2023|main.py|INFO] EPOCH [1/100] Learning rate: 0.50000
[Fri Apr 21 16:38:59 2023|main.py|INFO] EPOCH [1/100] NME improved from 1000.00000 to 0.29142
[Fri Apr 21 16:38:59 2023|main.py|INFO] EPOCH [1/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_16-38-59_epoch_1_NME_0.29142.pth.tar
[Fri Apr 21 16:53:50 2023|main.py|INFO] EPOCH [2/100] Train NME: 0.21514
[Fri Apr 21 16:53:51 2023|main.py|INFO] EPOCH [2/100] Test NME: 0.24543
[Fri Apr 21 16:53:51 2023|main.py|INFO] EPOCH [2/100] Learning rate: 0.40000
[Fri Apr 21 16:53:51 2023|main.py|INFO] EPOCH [2/100] NME improved from 0.29142 to 0.24543
[Fri Apr 21 16:53:51 2023|main.py|INFO] EPOCH [2/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_16-53-51_epoch_2_NME_0.24543.pth.tar
[Fri Apr 21 17:09:29 2023|main.py|INFO] EPOCH [3/100] Train NME: 0.18816
[Fri Apr 21 17:09:30 2023|main.py|INFO] EPOCH [3/100] Test NME: 0.16598
[Fri Apr 21 17:09:30 2023|main.py|INFO] EPOCH [3/100] Learning rate: 0.32000
[Fri Apr 21 17:09:30 2023|main.py|INFO] EPOCH [3/100] NME improved from 0.24543 to 0.16598
[Fri Apr 21 17:09:30 2023|main.py|INFO] EPOCH [3/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_17-09-30_epoch_3_NME_0.16598.pth.tar
[Fri Apr 21 17:25:05 2023|main.py|INFO] EPOCH [4/100] Train NME: 0.17264
[Fri Apr 21 17:25:06 2023|main.py|INFO] EPOCH [4/100] Test NME: 0.18917
[Fri Apr 21 17:25:06 2023|main.py|INFO] EPOCH [4/100] Learning rate: 0.25600
[Fri Apr 21 17:39:45 2023|main.py|INFO] EPOCH [5/100] Train NME: 0.16424
[Fri Apr 21 17:39:46 2023|main.py|INFO] EPOCH [5/100] Test NME: 0.18936
[Fri Apr 21 17:39:46 2023|main.py|INFO] EPOCH [5/100] Learning rate: 0.20480
[Fri Apr 21 17:53:36 2023|main.py|INFO] EPOCH [6/100] Train NME: 0.16023
[Fri Apr 21 17:53:37 2023|main.py|INFO] EPOCH [6/100] Test NME: 0.16352
[Fri Apr 21 17:53:37 2023|main.py|INFO] EPOCH [6/100] Learning rate: 0.16384
[Fri Apr 21 17:53:37 2023|main.py|INFO] EPOCH [6/100] NME improved from 0.16598 to 0.16352
[Fri Apr 21 17:53:37 2023|main.py|INFO] EPOCH [6/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_17-53-37_epoch_6_NME_0.16352.pth.tar
[Fri Apr 21 18:08:10 2023|main.py|INFO] EPOCH [7/100] Train NME: 0.15812
[Fri Apr 21 18:08:11 2023|main.py|INFO] EPOCH [7/100] Test NME: 0.16114
[Fri Apr 21 18:08:11 2023|main.py|INFO] EPOCH [7/100] Learning rate: 0.13107
[Fri Apr 21 18:08:11 2023|main.py|INFO] EPOCH [7/100] NME improved from 0.16352 to 0.16114
[Fri Apr 21 18:08:11 2023|main.py|INFO] EPOCH [7/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_18-08-11_epoch_7_NME_0.16114.pth.tar
[Fri Apr 21 18:22:33 2023|main.py|INFO] EPOCH [8/100] Train NME: 0.15038
[Fri Apr 21 18:22:34 2023|main.py|INFO] EPOCH [8/100] Test NME: 0.14534
[Fri Apr 21 18:22:34 2023|main.py|INFO] EPOCH [8/100] Learning rate: 0.10486
[Fri Apr 21 18:22:34 2023|main.py|INFO] EPOCH [8/100] NME improved from 0.16114 to 0.14534
[Fri Apr 21 18:22:34 2023|main.py|INFO] EPOCH [8/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_18-22-34_epoch_8_NME_0.14534.pth.tar
[Fri Apr 21 18:36:33 2023|main.py|INFO] EPOCH [9/100] Train NME: 0.14840
[Fri Apr 21 18:36:34 2023|main.py|INFO] EPOCH [9/100] Test NME: 0.15153
[Fri Apr 21 18:36:34 2023|main.py|INFO] EPOCH [9/100] Learning rate: 0.08389
[Fri Apr 21 18:49:57 2023|main.py|INFO] EPOCH [10/100] Train NME: 0.14664
[Fri Apr 21 18:49:58 2023|main.py|INFO] EPOCH [10/100] Test NME: 0.15287
[Fri Apr 21 18:49:58 2023|main.py|INFO] EPOCH [10/100] Learning rate: 0.06711
[Fri Apr 21 19:25:41 2023|main.py|INFO] EPOCH [11/100] Train NME: 0.14300
[Fri Apr 21 19:25:43 2023|main.py|INFO] EPOCH [11/100] Test NME: 0.15584
[Fri Apr 21 19:25:43 2023|main.py|INFO] EPOCH [11/100] Learning rate: 0.05369
[Fri Apr 21 19:50:17 2023|main.py|INFO] EPOCH [12/100] Train NME: 0.14181
[Fri Apr 21 19:50:19 2023|main.py|INFO] EPOCH [12/100] Test NME: 0.14317
[Fri Apr 21 19:50:19 2023|main.py|INFO] EPOCH [12/100] Learning rate: 0.04295
[Fri Apr 21 19:50:19 2023|main.py|INFO] EPOCH [12/100] NME improved from 0.14534 to 0.14317
[Fri Apr 21 19:50:19 2023|main.py|INFO] EPOCH [12/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_19-50-19_epoch_12_NME_0.14317.pth.tar
[Fri Apr 21 20:16:04 2023|main.py|INFO] EPOCH [13/100] Train NME: 0.14257
[Fri Apr 21 20:16:06 2023|main.py|INFO] EPOCH [13/100] Test NME: 0.14796
[Fri Apr 21 20:16:06 2023|main.py|INFO] EPOCH [13/100] Learning rate: 0.03436
[Fri Apr 21 20:39:38 2023|main.py|INFO] EPOCH [14/100] Train NME: 0.14116
[Fri Apr 21 20:39:40 2023|main.py|INFO] EPOCH [14/100] Test NME: 0.15494
[Fri Apr 21 20:39:40 2023|main.py|INFO] EPOCH [14/100] Learning rate: 0.02749
[Fri Apr 21 21:00:45 2023|main.py|INFO] EPOCH [15/100] Train NME: 0.14154
[Fri Apr 21 21:00:46 2023|main.py|INFO] EPOCH [15/100] Test NME: 0.14881
[Fri Apr 21 21:00:46 2023|main.py|INFO] EPOCH [15/100] Learning rate: 0.02199
[Fri Apr 21 21:14:23 2023|main.py|INFO] EPOCH [16/100] Train NME: 0.14008
[Fri Apr 21 21:14:25 2023|main.py|INFO] EPOCH [16/100] Test NME: 0.14449
[Fri Apr 21 21:14:25 2023|main.py|INFO] EPOCH [16/100] Learning rate: 0.01759
[Fri Apr 21 21:41:03 2023|main.py|INFO] EPOCH [17/100] Train NME: 0.13721
[Fri Apr 21 21:41:05 2023|main.py|INFO] EPOCH [17/100] Test NME: 0.14279
[Fri Apr 21 21:41:05 2023|main.py|INFO] EPOCH [17/100] Learning rate: 0.01407
[Fri Apr 21 21:41:05 2023|main.py|INFO] EPOCH [17/100] NME improved from 0.14317 to 0.14279
[Fri Apr 21 21:41:05 2023|main.py|INFO] EPOCH [17/100] Saving model to: checkpoints/Cas_Stage1_Aug_Wing_lr0.5_B4/2023-04-21_21-41-05_epoch_17_NME_0.14279.pth.tar
[Fri Apr 21 22:06:44 2023|main.py|INFO] EPOCH [18/100] Train NME: 0.13599
[Fri Apr 21 22:06:45 2023|main.py|INFO] EPOCH [18/100] Test NME: 0.14447
[Fri Apr 21 22:06:45 2023|main.py|INFO] EPOCH [18/100] Learning rate: 0.01126
[Fri Apr 21 22:31:42 2023|main.py|INFO] EPOCH [19/100] Train NME: 0.13525
[Fri Apr 21 22:31:44 2023|main.py|INFO] EPOCH [19/100] Test NME: 0.14937
[Fri Apr 21 22:31:44 2023|main.py|INFO] EPOCH [19/100] Learning rate: 0.00901
[Fri Apr 21 22:57:37 2023|main.py|INFO] EPOCH [20/100] Train NME: 0.13345
[Fri Apr 21 22:57:38 2023|main.py|INFO] EPOCH [20/100] Test NME: 0.14790
[Fri Apr 21 22:57:38 2023|main.py|INFO] EPOCH [20/100] Learning rate: 0.00721
